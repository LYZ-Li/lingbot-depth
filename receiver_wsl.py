import os
import time
import zmq
import numpy as np
import torch
import cv2
import rerun as rr
import warnings

# === ç¦ç”¨ä¸å¿…è¦çš„è­¦å‘Š ===
os.environ["XFORMERS_DISABLED"] = "1"
warnings.filterwarnings("ignore")

from mdm.model.v2 import MDMModel

# === é…ç½® ===
PORT = 5555
MODEL_PATH = "robbyant/lingbot-depth-pretrain-vitl-14" 

def main():
    print(f"ğŸ“¦ Rerun SDK Version: {rr.__version__}")
    
    # 1. åˆå§‹åŒ– Web Viewer
    rr.init("LingBot_Live", spawn=True)
    
    # âœ… ä½ å‘ç°çš„æ­£ç¡®å†™æ³•
    print("ğŸŒ å¯åŠ¨ Web Server...")
    try:
        # å†™æ³• A: é’ˆå¯¹éƒ¨åˆ†ç‰ˆæœ¬çš„å†™æ³•
        rr.start_web_viewer_server(port=9090, host="0.0.0.0")
    except TypeError:
        try:
            # å†™æ³• B: é’ˆå¯¹å¦ä¸€éƒ¨åˆ†ç‰ˆæœ¬çš„å†™æ³•
            rr.start_web_viewer_server("0.0.0.0:9090")
        except TypeError:
            # å†™æ³• C: å¦‚æœéƒ½ä¸è¡Œï¼Œå›é€€åˆ°é»˜è®¤ï¼Œç„¶åæˆ‘ä»¬è¦ç”¨æ–¹æ³•äºŒ (socat)
            print("âš ï¸ æ— æ³•é€šè¿‡ä»£ç ç»‘å®š IPï¼Œå°†ä½¿ç”¨é»˜è®¤ localhost")
            rr.start_web_viewer_server()
    
    print("\nğŸŒ ==========================================")
    print("   è¯·åœ¨ Windows æµè§ˆå™¨æ‰“å¼€ä»¥ä¸‹åœ°å€æŸ¥çœ‹å¯è§†åŒ–:")
    print("   http://localhost:9090")
    print("   ==========================================\n")

    # 2. åŠ è½½æ¨¡å‹
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ§  æ­£åœ¨åŠ è½½æ¨¡å‹åˆ° {device}...")
    try:
        model = MDMModel.from_pretrained(MODEL_PATH).to(device)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•åŠ è½½æœ¬åœ°å¤‡ä»½... ({e})")
        model = MDMModel.from_pretrained("ckpt/model.pt").to(device)
    
    model.eval()
    print("âœ… æ¨¡å‹å°±ç»ª!")

    # 3. ZMQ åå‘è¿æ¥
    context = zmq.Context()
    socket = context.socket(zmq.SUB)
    
    print(f"ğŸ‘‚ æ­£åœ¨ç›‘å¬ç«¯å£ {PORT}ï¼Œç­‰å¾… Windows è¿æ¥...")
    socket.bind(f"tcp://0.0.0.0:{PORT}")
    
    socket.setsockopt_string(zmq.SUBSCRIBE, "") 
    socket.setsockopt(zmq.CONFLATE, 1)

    # å¢åŠ ä¸€ä¸ªå¸§è®¡æ•°å™¨ï¼Œä¸‡ä¸€éœ€è¦ç”¨å®ƒæ¥åšæ—¶é—´è½´
    frame_count = 0

    try:
        while True:
            # 4. æ¥æ”¶æ•°æ®
            header = socket.recv_json()
            depth_bytes = socket.recv()
            color_bytes = socket.recv()

            w, h = header["w"], header["h"]
            intr = header["intr"]
            
            # 5. è§£ç æ•°æ®
            raw_depth_mm = np.frombuffer(depth_bytes, dtype=np.uint16).reshape(h, w)
            depth_m = raw_depth_mm.astype(np.float32) / 1000.0
            
            raw_rgb_bgr = np.frombuffer(color_bytes, dtype=np.uint8).reshape(h, w, 3)
            raw_rgb = cv2.cvtColor(raw_rgb_bgr, cv2.COLOR_BGR2RGB)
            
            # 6. æ¨ç†
            img_tensor = torch.from_numpy(raw_rgb).float().to(device) / 255.0
            img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)
            depth_tensor = torch.from_numpy(depth_m).float().to(device)

            K = np.array([
                [intr['fx'], 0,          intr['ppx']],
                [0,          intr['fy'], intr['ppy']],
                [0,          0,          1]
            ], dtype=np.float32)
            
            K_norm = K.copy()
            K_norm[0, 0] /= w; K_norm[0, 2] /= w
            K_norm[1, 1] /= h; K_norm[1, 2] /= h
            intrinsics_tensor = torch.from_numpy(K_norm).unsqueeze(0).to(device)

            # è®¡æ—¶æ¨ç†è€—æ—¶
            t_infer_start = time.time()
            with torch.no_grad():
                output = model.infer(
                    img_tensor, depth_in=depth_tensor, apply_mask=True, intrinsics=intrinsics_tensor
                )
            t_infer_duration = time.time() - t_infer_start
            pred_depth = output['depth'].squeeze().cpu().numpy()
            
            # ==========================================================
            # 7. Rerun å¯è§†åŒ– (å…³é”®ä¿®å¤éƒ¨åˆ†)
            # ==========================================================
            
            # ä¿®å¤æ–¹æ¡ˆï¼šå°è¯•è®¾ç½®æ—¶é—´è½´ï¼Œå¦‚æœæŠ¥é”™å°±è·³è¿‡ï¼Œä¸å½±å“æ˜¾ç¤º
            try:
                # ä¼˜å…ˆå°è¯•ç”¨æ•´æ•°å¸§å·ï¼Œé€šå¸¸æ¯” set_time_seconds ç¨³å®š
                if hasattr(rr, 'set_time_sequence'):
                    rr.set_time_sequence("frame_idx", frame_count)
                elif hasattr(rr, 'set_time_seconds'):
                    rr.set_time_seconds("capture_time", header["t"])
                else:
                    # å¦‚æœå•¥éƒ½æ²¡æœ‰ï¼Œå°±ä»€ä¹ˆéƒ½ä¸åšï¼ŒRerun ä¼šè‡ªåŠ¨æŒ‰æ¥æ”¶æ—¶é—´æ’åº
                    pass
            except Exception:
                pass # å¿½ç•¥æ‰€æœ‰æ—¶é—´è®¾ç½®é”™è¯¯

            rr.log("camera/rgb", rr.Image(raw_rgb))
            rr.log("camera/depth/raw", rr.DepthImage(raw_depth_mm, meter=1000))
            rr.log("camera/depth/refined", rr.DepthImage(pred_depth, meter=1)) 
            rr.log("camera", rr.Pinhole(resolution=[w, h], image_from_camera=K))

            # æ‰“å°çŠ¶æ€
            if frame_count % 30 == 0:
                 print(f"\rğŸš€ Running... Infer: {t_infer_duration*1000:.1f}ms", end="")
            
            frame_count += 1

    except KeyboardInterrupt:
        print("\nğŸ›‘ é€€å‡º...")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()