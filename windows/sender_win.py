import pyrealsense2 as rs
import numpy as np
import zmq
import time
import json
import subprocess
import re

PORT = 5555
WIDTH, HEIGHT = 640, 480
FPS = 30

def get_wsl_ip():
    """é€šè¿‡è¿è¡Œ wsl å‘½ä»¤èŽ·å– WSL è™šæ‹Ÿæœºçš„ IP åœ°å€"""
    try:
        # è¿è¡Œ wsl hostname -I èŽ·å– IP
        result = subprocess.run(["wsl", "hostname", "-I"], capture_output=True, text=True)
        ip = result.stdout.strip().split(' ')[0]
        if ip:
            return ip
    except Exception:
        pass
    print("âŒ æ— æ³•è‡ªåŠ¨èŽ·å– WSL IPï¼Œè¯·æ‰‹åŠ¨è¾“å…¥")
    return input("è¯·è¾“å…¥ WSL çš„ IP åœ°å€ (åœ¨ WSL è¾“å…¥ hostname -I æŸ¥çœ‹): ").strip()

def main():
    # --- å¯åŠ¨ RealSense (ä¿æŒä¸å˜) ---
    pipeline = rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth, WIDTH, HEIGHT, rs.format.z16, FPS)
    config.enable_stream(rs.stream.color, WIDTH, HEIGHT, rs.format.bgr8, FPS)
    align = rs.align(rs.stream.color)
    
    print("ðŸ“· å¯åŠ¨ç›¸æœº...")
    profile = pipeline.start(config)
    
    # èŽ·å–å†…å‚
    intr = profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()
    intrinsics_dict = {"fx": intr.fx, "fy": intr.fy, "ppx": intr.ppx, "ppy": intr.ppy}

    # --- ZMQ æ”¹åŠ¨éƒ¨åˆ† ---
    wsl_ip = get_wsl_ip()
    print(f"ðŸŽ¯ ç›®æ ‡ WSL IP: {wsl_ip}")
    
    context = zmq.Context()
    socket = context.socket(zmq.PUB)
    
    # âš ï¸ å…³é”®æ”¹åŠ¨ï¼šè¿™é‡Œä¸å†æ˜¯ bindï¼Œè€Œæ˜¯ connect
    target_addr = f"tcp://{wsl_ip}:{PORT}"
    print(f"ðŸ“¡ æ­£åœ¨å°è¯•ç©¿é€é˜²ç«å¢™è¿žæŽ¥åˆ°: {target_addr}")
    socket.connect(target_addr)

    frame_count = 0
    try:
        while True:
            frames = pipeline.wait_for_frames()
            aligned_frames = align.process(frames)
            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()
            if not depth_frame or not color_frame: continue

            depth_image = np.asanyarray(depth_frame.get_data())
            color_image = np.asanyarray(color_frame.get_data())

            header = {
                "t": time.time(),
                "w": WIDTH, "h": HEIGHT,
                "seq": frame_count,
                "intr": intrinsics_dict
            }
            
            socket.send_json(header, flags=zmq.SNDMORE)
            socket.send(depth_image.tobytes(), flags=zmq.SNDMORE)
            socket.send(color_image.tobytes())

            if frame_count % 30 == 0:
                print(f"\rðŸš€ Sending frame {frame_count} -> WSL", end="")
            frame_count += 1

    except KeyboardInterrupt:
        pass
    finally:
        pipeline.stop()

if __name__ == "__main__":
    main()